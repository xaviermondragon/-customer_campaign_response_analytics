{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Campaign Response Analytics Using PySpark"
      ],
      "metadata": {
        "id": "awvOG90HwPTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset can be found at [kaggle](https://www.kaggle.com/datasets/nimishsawant/bankfull). The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y)."
      ],
      "metadata": {
        "id": "yBbGY-fEHdnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion from CSV to Spark DataFrame"
      ],
      "metadata": {
        "id": "xX44GDERxFpi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-9gUBf4wHxH",
        "outputId": "ff37dda6-46f7-44cc-a7ab-78b5cd1eeb7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q findspark # -q, --quiet Give less output"
      ],
      "metadata": {
        "id": "BSKmSK7UxMoS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "JuT3jqmYxhik"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark Session\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Customer Campaign Response Analytics').getOrCreate()"
      ],
      "metadata": {
        "id": "kK7lWFg3xtRd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/bank-full.csv'\n",
        "\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "# Which variables do we have?\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzUR3YDyX3i",
        "outputId": "02d1a3ac-c3c4-4bfe-a3d3-0a7b169c20b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- Target: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How does the data look like?\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Y0rDsnzNNP",
        "outputId": "8915472e-8cae-4629-cb13-ee844850c31e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|Target|\n",
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown|    no|\n",
            "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown|    no|\n",
            "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown|    no|\n",
            "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown|    no|\n",
            "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown|    no|\n",
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each datapoint contains information about a particular client, which was contacted during the marketing campaign mentioned at the beginning of this notebook. Most of the columns are self-explanatory, nevertheless, there are some for which an extra explanation is useful. For the sake of completeness, we include the description of each column:\n",
        "\n",
        "- **age**: Age\n",
        "- **job**: Occupation\n",
        "- **marital**: Marital Status\n",
        "- **education**: Education Level\n",
        "- **default**: Has credit in default?\n",
        "- **balance**: Average yearly balance\n",
        "- **housing**: Average has housing loan?\n",
        "- **loan**: Has personal loan?\n",
        "- **contact**: Contact communication type\n",
        "- **day**: Last contact day of the week\n",
        "- **month**: Last contact month of year\n",
        "- **duration**: Last contact duration, in seconds\n",
        "- **campaign**: Number of contacts performed during this campaign and for this client\n",
        "- **pdays**: Number of days that passed by after the client was last contacted from a previous campaign\n",
        "- **previous**: Number of contacts performed before this campaign and for this client\n",
        "- **poutcome**: Outcome of the previous marketing campaign\n",
        "- **Target**: Has the client subscribed a term deposit?\n",
        "\n",
        "As its name suggests, **Target** is the target variable, which we would like to predict."
      ],
      "metadata": {
        "id": "zqOAWR1rG0TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "-cgb_wiJEd8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column renaming"
      ],
      "metadata": {
        "id": "ehOSCelSNwPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do all the cleaning in a copy of the original dataframe\n",
        "df_clean = df.withColumnRenamed('Target', 'y')"
      ],
      "metadata": {
        "id": "P7Ds0DXvN1bN"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values:"
      ],
      "metadata": {
        "id": "iDE3q0c6FbrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import isnull, col, sum\n",
        "\n",
        "null_summary = df_clean.select(\n",
        "    [sum(col(c).isNull().cast('int')).alias(c) for c in df_clean.columns]\n",
        ")\n",
        "\n",
        "null_summary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1tsn9STEiz4",
        "outputId": "6a4ed203-942e-439a-a886-3653177de65e"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|  0|  0|      0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|  0|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Variables"
      ],
      "metadata": {
        "id": "ymWE_YJmP6FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.select('month').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5I0pPq7P_I5",
        "outputId": "cb8a6c4b-121f-44be-bfc6-19bb0bb4f25d"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|month|\n",
            "+-----+\n",
            "|  jun|\n",
            "|  aug|\n",
            "|  may|\n",
            "|  feb|\n",
            "|  sep|\n",
            "|  mar|\n",
            "|  oct|\n",
            "|  jul|\n",
            "|  nov|\n",
            "|  apr|\n",
            "|  dec|\n",
            "|  jan|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 12 months of the year are present. There is no 'year' column in the dataset and I also don't find any reference of the year(s) where the marketing campaign took place. We could assume that the campaign was run on a single year, but we can't be really sure. As we culd be dealing with more than one year, it is safer to perform cyclic encoding for month."
      ],
      "metadata": {
        "id": "n9W8XKQwQyow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert month to a numerical variable\n",
        "from pyspark.sql.functions import from_unixtime, unix_timestamp\n",
        "\n",
        "df_clean = df_clean.withColumn('month', from_unixtime(unix_timestamp(col('month'), 'MMM'), 'MM'))\n",
        "df_clean = df_clean.withColumn('month', df_clean['month'].cast('int'))\n",
        "df_clean.select('month').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R07_rJB54i5c",
        "outputId": "de04fca1-1f6f-42b0-abdb-9487b840ca61"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|month|\n",
            "+-----+\n",
            "|   12|\n",
            "|    1|\n",
            "|    6|\n",
            "|    3|\n",
            "|    5|\n",
            "|    9|\n",
            "|    4|\n",
            "|    8|\n",
            "|    7|\n",
            "|   10|\n",
            "|   11|\n",
            "|    2|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cyclical encoding\n",
        "from pyspark.sql.functions import sin, cos\n",
        "from math import pi\n",
        "df_clean = df_clean.withColumn('month_sin', sin(2*pi*(df_clean['month'] - 1)/12))\n",
        "df_clean = df_clean.withColumn('month_cos', sin(2*pi*(df_clean['month'] - 1)/12))\n",
        "df_clean.drop('month', inplace = True)"
      ],
      "metadata": {
        "id": "8N88zxqH-hZa"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.toPandas().to_csv('/content/clean_data.csv')"
      ],
      "metadata": {
        "id": "Lw78JOUMDGxg"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}