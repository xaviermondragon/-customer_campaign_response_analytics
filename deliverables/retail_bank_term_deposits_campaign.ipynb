{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Customer Campaign Response Analytics Using PySpark"
      ],
      "metadata": {
        "id": "awvOG90HwPTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset can be found at [kaggle](https://www.kaggle.com/datasets/nimishsawant/bankfull). The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y)."
      ],
      "metadata": {
        "id": "yBbGY-fEHdnL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion from CSV to Spark DataFrame"
      ],
      "metadata": {
        "id": "xX44GDERxFpi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-9gUBf4wHxH",
        "outputId": "ae1cea2c-2a71-4acc-c7d6-0a006e932585"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q findspark # -q, --quiet Give less output"
      ],
      "metadata": {
        "id": "BSKmSK7UxMoS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()"
      ],
      "metadata": {
        "id": "JuT3jqmYxhik"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Spark Session\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName('Customer Campaign Response Analytics').getOrCreate()"
      ],
      "metadata": {
        "id": "kK7lWFg3xtRd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "file_path = '/content/bank-full.csv'\n",
        "\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "# Which variables do we have?\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGzUR3YDyX3i",
        "outputId": "beda5161-bc3c-4090-d487-0237c4a9b755"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- age: integer (nullable = true)\n",
            " |-- job: string (nullable = true)\n",
            " |-- marital: string (nullable = true)\n",
            " |-- education: string (nullable = true)\n",
            " |-- default: string (nullable = true)\n",
            " |-- balance: integer (nullable = true)\n",
            " |-- housing: string (nullable = true)\n",
            " |-- loan: string (nullable = true)\n",
            " |-- contact: string (nullable = true)\n",
            " |-- day: integer (nullable = true)\n",
            " |-- month: string (nullable = true)\n",
            " |-- duration: integer (nullable = true)\n",
            " |-- campaign: integer (nullable = true)\n",
            " |-- pdays: integer (nullable = true)\n",
            " |-- previous: integer (nullable = true)\n",
            " |-- poutcome: string (nullable = true)\n",
            " |-- Target: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# How does the data look like?\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2Y0rDsnzNNP",
        "outputId": "b2eb8e09-de6e-43f1-f3e8-230d283ef03e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "|age|         job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|Target|\n",
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "| 58|  management|married| tertiary|     no|   2143|    yes|  no|unknown|  5|  may|     261|       1|   -1|       0| unknown|    no|\n",
            "| 44|  technician| single|secondary|     no|     29|    yes|  no|unknown|  5|  may|     151|       1|   -1|       0| unknown|    no|\n",
            "| 33|entrepreneur|married|secondary|     no|      2|    yes| yes|unknown|  5|  may|      76|       1|   -1|       0| unknown|    no|\n",
            "| 47| blue-collar|married|  unknown|     no|   1506|    yes|  no|unknown|  5|  may|      92|       1|   -1|       0| unknown|    no|\n",
            "| 33|     unknown| single|  unknown|     no|      1|     no|  no|unknown|  5|  may|     198|       1|   -1|       0| unknown|    no|\n",
            "+---+------------+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each datapoint contains information about a particular client, which was contacted during the marketing campaign mentioned at the beginning of this notebook. Most of the columns are self-explanatory, nevertheless, there are some for which an extra explanation is useful. For the sake of completeness, we include the description of each column:\n",
        "\n",
        "- **age**: Age\n",
        "- **job**: Occupation\n",
        "- **marital**: Marital Status\n",
        "- **education**: Education Level\n",
        "- **default**: Has credit in default?\n",
        "- **balance**: Average yearly balance\n",
        "- **housing**: Average has housing loan?\n",
        "- **loan**: Has personal loan?\n",
        "- **contact**: Contact communication type\n",
        "- **day**: Last contact day of the month (In the data description it says day of the week, but wee will see below that's not the case)\n",
        "- **month**: Last contact month of year\n",
        "- **duration**: Last contact duration, in seconds\n",
        "- **campaign**: Number of contacts performed during this campaign and for this client\n",
        "- **pdays**: Number of days that passed by after the client was last contacted from a previous campaign\n",
        "- **previous**: Number of contacts performed before this campaign and for this client\n",
        "- **poutcome**: Outcome of the previous marketing campaign\n",
        "- **Target**: Has the client subscribed a term deposit?\n",
        "\n",
        "As its name suggests, **Target** is the target variable, which we would like to predict."
      ],
      "metadata": {
        "id": "zqOAWR1rG0TA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning and Preprocessing"
      ],
      "metadata": {
        "id": "-cgb_wiJEd8Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Column renaming"
      ],
      "metadata": {
        "id": "ehOSCelSNwPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Do all the cleaning in a copy of the original dataframe\n",
        "df_clean = df.withColumnRenamed('Target', 'y')"
      ],
      "metadata": {
        "id": "P7Ds0DXvN1bN"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Missing Values:"
      ],
      "metadata": {
        "id": "iDE3q0c6FbrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import isnull, col, sum\n",
        "\n",
        "null_summary = df_clean.select(\n",
        "    [sum(col(c).isNull().cast('int')).alias(c) for c in df_clean.columns]\n",
        ")\n",
        "\n",
        "null_summary.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1tsn9STEiz4",
        "outputId": "b5fcfb10-005f-4917-bcc0-7005744fd139"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|age|job|marital|education|default|balance|housing|loan|contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "|  0|  0|      0|        0|      0|      0|      0|   0|      0|  0|    0|       0|       0|    0|       0|       0|  0|\n",
            "+---+---+-------+---------+-------+-------+-------+----+-------+---+-----+--------+--------+-----+--------+--------+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Variables"
      ],
      "metadata": {
        "id": "ymWE_YJmP6FI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.select('month').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5I0pPq7P_I5",
        "outputId": "8caf18a5-3c35-41fd-a87d-da40384a5483"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|month|\n",
            "+-----+\n",
            "|  jun|\n",
            "|  aug|\n",
            "|  may|\n",
            "|  feb|\n",
            "|  sep|\n",
            "|  mar|\n",
            "|  oct|\n",
            "|  jul|\n",
            "|  nov|\n",
            "|  apr|\n",
            "|  dec|\n",
            "|  jan|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All 12 months of the year are present. There is no 'year' column in the dataset and I also don't find any reference of the year(s) where the marketing campaign took place. We could assume that the campaign was run on a single year, but we can't be really sure. As we culd be dealing with more than one year, it is safer to perform cyclic encoding for month."
      ],
      "metadata": {
        "id": "n9W8XKQwQyow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# First convert month to a numerical variable\n",
        "from pyspark.sql.functions import from_unixtime, unix_timestamp\n",
        "\n",
        "df_clean = df_clean.withColumn('month', from_unixtime(unix_timestamp(col('month'), 'MMM'), 'MM'))\n",
        "df_clean = df_clean.withColumn('month', df_clean['month'].cast('int'))\n",
        "df_clean.select('month').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R07_rJB54i5c",
        "outputId": "69ba5901-2420-430b-d5fa-70a6156d711f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+\n",
            "|month|\n",
            "+-----+\n",
            "|   12|\n",
            "|    1|\n",
            "|    6|\n",
            "|    3|\n",
            "|    5|\n",
            "|    9|\n",
            "|    4|\n",
            "|    8|\n",
            "|    7|\n",
            "|   10|\n",
            "|   11|\n",
            "|    2|\n",
            "+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cyclical encoding of month\n",
        "from pyspark.sql.functions import sin, cos\n",
        "from math import pi\n",
        "df_clean = df_clean.withColumn('month_sin', sin(2*pi*(df_clean['month'] - 1)/12))\n",
        "df_clean = df_clean.withColumn('month_cos', sin(2*pi*(df_clean['month'] - 1)/12))"
      ],
      "metadata": {
        "id": "8N88zxqH-hZa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now take a look at the **day** column:"
      ],
      "metadata": {
        "id": "hhOb4dt0xrbm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_clean.select('day').distinct().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df7KD7J0h9zg",
        "outputId": "a51436bc-4f29-4895-ca60-e798057c5c29"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "|day|\n",
            "+---+\n",
            "| 31|\n",
            "| 28|\n",
            "| 26|\n",
            "| 27|\n",
            "| 12|\n",
            "| 22|\n",
            "|  1|\n",
            "| 13|\n",
            "|  6|\n",
            "| 16|\n",
            "|  3|\n",
            "| 20|\n",
            "|  5|\n",
            "| 19|\n",
            "| 15|\n",
            "|  9|\n",
            "| 17|\n",
            "|  4|\n",
            "|  8|\n",
            "| 23|\n",
            "+---+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As mentioned on the introduction, we are dealing with day of the month instead of day of the week. Let's perform cyclical encoding accordingly."
      ],
      "metadata": {
        "id": "kIOpPVrLiw_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# create an auxiliar column having the number of days in a given month\n",
        "df_clean = df_clean.withColumn(\n",
        "    'month_days',\n",
        "    F.when(F.col('month').isin([1, 3, 5, 7, 8, 10, 12]), 31) #months with 31 days\n",
        "    .when(F.col('month').isin([4, 6, 9, 11]), 30) # months with 30 days\n",
        "    .otherwise(28) # february\n",
        ")"
      ],
      "metadata": {
        "id": "1Z2G-UF1tdED"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cyclical encoding of day\n",
        "df_clean = df_clean.withColumn('day_sin', sin(2*pi*(df_clean['day'] - 1)/df_clean['month_days']))\n",
        "df_clean = df_clean.withColumn('day_cos', sin(2*pi*(df_clean['day'] - 1)/df_clean['month_days']))\n",
        "# drop auxiliar column\n",
        "df_clean = df_clean.drop('month_days')"
      ],
      "metadata": {
        "id": "ym-A3fF_7jfe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploration of categorical columns"
      ],
      "metadata": {
        "id": "z0WbxJWm98de"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categorical = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'poutcome']\n",
        "\n",
        "for col in categorical:\n",
        "  df_clean.groupBy(col).count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNJhVAmGBMCR",
        "outputId": "8036913c-4ab3-460a-bf36-ae88674531e8"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|          job|count|\n",
            "+-------------+-----+\n",
            "|   management| 9458|\n",
            "|      retired| 2264|\n",
            "|      unknown|  288|\n",
            "|self-employed| 1579|\n",
            "|      student|  938|\n",
            "|  blue-collar| 9732|\n",
            "| entrepreneur| 1487|\n",
            "|       admin.| 5171|\n",
            "|   technician| 7597|\n",
            "|     services| 4154|\n",
            "|    housemaid| 1240|\n",
            "|   unemployed| 1303|\n",
            "+-------------+-----+\n",
            "\n",
            "+--------+-----+\n",
            "| marital|count|\n",
            "+--------+-----+\n",
            "|divorced| 5207|\n",
            "| married|27214|\n",
            "|  single|12790|\n",
            "+--------+-----+\n",
            "\n",
            "+---------+-----+\n",
            "|education|count|\n",
            "+---------+-----+\n",
            "|  unknown| 1857|\n",
            "| tertiary|13301|\n",
            "|secondary|23202|\n",
            "|  primary| 6851|\n",
            "+---------+-----+\n",
            "\n",
            "+-------+-----+\n",
            "|default|count|\n",
            "+-------+-----+\n",
            "|     no|44396|\n",
            "|    yes|  815|\n",
            "+-------+-----+\n",
            "\n",
            "+-------+-----+\n",
            "|housing|count|\n",
            "+-------+-----+\n",
            "|     no|20081|\n",
            "|    yes|25130|\n",
            "+-------+-----+\n",
            "\n",
            "+----+-----+\n",
            "|loan|count|\n",
            "+----+-----+\n",
            "|  no|37967|\n",
            "| yes| 7244|\n",
            "+----+-----+\n",
            "\n",
            "+---------+-----+\n",
            "|  contact|count|\n",
            "+---------+-----+\n",
            "|  unknown|13020|\n",
            "| cellular|29285|\n",
            "|telephone| 2906|\n",
            "+---------+-----+\n",
            "\n",
            "+--------+-----+\n",
            "|poutcome|count|\n",
            "+--------+-----+\n",
            "| success| 1511|\n",
            "| unknown|36959|\n",
            "|   other| 1840|\n",
            "| failure| 4901|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean Data Saving"
      ],
      "metadata": {
        "id": "qLw3dj1eg5Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df_clean.toPandas().to_csv('/content/clean_data.csv')"
      ],
      "metadata": {
        "id": "Lw78JOUMDGxg"
      },
      "execution_count": 15,
      "outputs": []
    }
  ]
}